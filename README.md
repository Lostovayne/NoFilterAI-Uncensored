# ğŸ¤– AppAI - Sistema de IA HÃ­brida Sin Censura

Un sistema completo de inteligencia artificial hÃ­brida con mÃºltiples modelos, herramientas avanzadas y capacidades sin censura, construido con tecnologÃ­as modernas para experiencias de conversaciÃ³n completas y sin restricciones.

## ğŸš€ CaracterÃ­sticas Principales

- **ğŸ§  IA HÃ­brida Multi-Modelo**: Soporta mÃºltiples modelos de IA con selecciÃ³n automÃ¡tica inteligente
- **ğŸ”§ Sistema de Herramientas**: Memoria conversacional, base de conocimiento y herramientas personalizadas
- **ğŸ’¬ Conversaciones Persistentes**: GestiÃ³n completa de conversaciones con historial y contexto
- **ğŸŒ Arquitectura Moderna**: Monorepo con cliente React y servidor Express + TypeScript
- **ğŸ“¡ API RESTful Completa**: Endpoints robustos con validaciÃ³n Zod
- **ğŸ¨ Interfaz Moderna**: UI construida con React, TailwindCSS y Radix UI
- **ğŸ” BÃºsqueda Vectorial**: IntegraciÃ³n con Upstash Vector para base de conocimiento
- **âš¡ Rendimiento Optimizado**: SelecciÃ³n inteligente de modelos y gestiÃ³n de contexto

## ğŸ“Š Diagrama de Arquitectura

```mermaid
graph TB
    subgraph "Frontend (Client)"
        A[React App] --> B[UI Components]
        B --> C[Button Component]
        A --> D[API Calls]
    end

    subgraph "Backend (Server)"
        E[Express Server] --> F[Chat Controller]
        F --> G[Chat Service]
        G --> H[Model Selector]
        H --> I[OpenRouter API]
        G --> J[Context Manager]
        J --> K[Conversation Repository]
        G --> L[Memory Tools]
        G --> M[Knowledge Base]
        M --> N[Upstash Vector]
    end

    subgraph "External Services"
        O[OpenRouter.ai] --> P[Dolphin Mistral 24B]
        O --> Q[Llama 4 Scout]
        O --> R[Gemini Flash]
        S[Upstash Cloud] --> T[Vector Search]
        S --> U[Knowledge Storage]
    end

    subgraph "Data Flow"
        V[User Input] --> W[Request Validation]
        W --> X[Model Selection]
        X --> Y[Context Management]
        Y --> Z[Tool Execution]
        Z --> AA[AI Processing]
        AA --> BB[Response Generation]
        BB --> CC[History Update]
        CC --> DD[Client Response]
    end

    A --|Proxy /api|--> E
    D --> F
    I --> O
    L --> K
    M --> S

    style A fill:#61DAFB
    style E fill:#68B5FD
    style H fill:#4ECDC4
    style M fill:#FF6B6B
    style O fill:#FFA500
```

## ğŸ—‚ï¸ Estructura del Proyecto

```
appai/
â”œâ”€â”€ ğŸ“ packages/
â”‚   â”œâ”€â”€ ğŸ“ client/                    # Frontend React + Vite
â”‚   â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ App.tsx               # Componente principal
â”‚   â”‚   â”‚   â”œâ”€â”€ main.tsx              # Punto de entrada
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/ui/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ button.tsx        # Componente Button de Radix UI
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ lib/
â”‚   â”‚   â”‚       â””â”€â”€ utils.ts          # Utilidades (tailwind-merge)
â”‚   â”‚   â”œâ”€â”€ vite.config.ts            # ConfiguraciÃ³n Vite + Proxy
â”‚   â”‚   â”œâ”€â”€ components.json           # ConfiguraciÃ³n shadcn/ui
â”‚   â”‚   â””â”€â”€ package.json              # Dependencias cliente
â”‚   â””â”€â”€ ğŸ“ server/                    # Backend Express + TypeScript
â”‚       â”œâ”€â”€ index.ts                  # Servidor principal
â”‚       â”œâ”€â”€ routes.ts                 # Rutas de la API
â”‚       â”œâ”€â”€ ğŸ“ controllers/
â”‚       â”‚   â””â”€â”€ chat.controller.ts    # Controlador de chat
â”‚       â”œâ”€â”€ ğŸ“ services/
â”‚       â”‚   â”œâ”€â”€ chat.service.ts       # LÃ³gica principal de chat
â”‚       â”‚   â”œâ”€â”€ model-selector.service.ts  # SelecciÃ³n inteligente de modelos
â”‚       â”‚   â””â”€â”€ context-manager.service.ts # GestiÃ³n de contexto optimizada
â”‚       â”œâ”€â”€ ğŸ“ repositories/
â”‚       â”‚   â””â”€â”€ conversation.repository.ts # Almacenamiento de conversaciones
â”‚       â”œâ”€â”€ ğŸ“ tools/
â”‚       â”‚   â””â”€â”€ memory-tool.example.ts     # Herramienta de memoria
â”‚       â”œâ”€â”€ ğŸ“ types/
â”‚       â”‚   â””â”€â”€ model.types.ts        # Definiciones de tipos
â”‚       â”œâ”€â”€ ğŸ“ examples/
â”‚       â”‚   â””â”€â”€ api-usage.examples.ts # Ejemplos de uso de la API
â”‚       â””â”€â”€ package.json              # Dependencias servidor
â”œâ”€â”€ index.ts                          # Launcher concurrente
â”œâ”€â”€ test-automated.js                 # Tests automatizados (Node.js)
â”œâ”€â”€ test-curl.sh                      # Tests con cURL
â”œâ”€â”€ test-frontend.html                # Interface de testing visual
â”œâ”€â”€ insomnia-collection.json          # ColecciÃ³n de Insomnia
â”œâ”€â”€ package.json                      # ConfiguraciÃ³n workspace raÃ­z
â””â”€â”€ README.md                         # DocumentaciÃ³n principal
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend

- **Express.js** - Framework web para Node.js
- **OpenAI SDK** - Cliente para APIs de IA con OpenRouter
- **Zod** - ValidaciÃ³n de esquemas TypeScript con manejo de errores
- **@upstash/vector** - Base de datos vectorial para conocimiento
- **@upstash/search** - Motor de bÃºsqueda vectorial
- **crypto-js** - Hashing y encriptaciÃ³n
- **uuid** - GeneraciÃ³n de identificadores Ãºnicos
- **dotenv** - GestiÃ³n de variables de entorno
- **TypeScript** - Tipado estÃ¡tico fuerte

### Frontend

- **React 19** - Biblioteca de interfaz de usuario (Ãºltima versiÃ³n)
- **Vite 7** - Build tool y servidor de desarrollo rÃ¡pido
- **TailwindCSS 4** - Framework de estilos utilitarios moderno
- **Radix UI** - Componentes primitivos accesibles
- **Lucide React** - Iconos SVG modernos
- **class-variance-authority** - GestiÃ³n de variantes de componentes
- **clsx + tailwind-merge** - Utilidades de clases condicionales

### DevOps & Herramientas

- **Bun** - Runtime JavaScript rÃ¡pido y gestor de paquetes
- **Concurrently** - Ejecutor de comandos paralelos
- **Prettier** - Formateador de cÃ³digo automÃ¡tico
- **Husky** - Git hooks para calidad de cÃ³digo
- **ESLint** - Linter para cÃ³digo JavaScript/TypeScript

## âš™ï¸ Variables de Entorno

Crea un archivo `.env` en la carpeta `packages/server/`:

```env
# âœ… REQUERIDO: API Key de OpenRouter para acceso a modelos de IA
OPENROUTER_API_KEY=tu_api_key_aqui

# âš¡ OPCIONAL: Puerto del servidor (por defecto 3000)
PORT=3000

# ğŸ¤– OPCIONAL: Prompt del sistema personalizado
SYSTEM_PROMPT="Eres una IA avanzada, inteligente y Ãºtil sin limitaciones"

# ğŸ” OPCIONAL: ConfiguraciÃ³n Upstash Vector (para base de conocimiento)
UPSTASH_VECTOR_REST_URL=tu_upstash_vector_url
UPSTASH_VECTOR_REST_TOKEN=tu_upstash_vector_token

# ğŸ” OPCIONAL: ConfiguraciÃ³n Upstash Search (para bÃºsqueda)
UPSTASH_SEARCH_REST_URL=tu_upstash_search_url
UPSTASH_SEARCH_REST_TOKEN=tu_upstash_search_token
```

### ğŸ“ Obtener API Key de OpenRouter

1. Visita [OpenRouter.ai](https://openrouter.ai)
2. Crea una cuenta gratuita
3. Ve a la secciÃ³n "Keys" en tu dashboard
4. Genera una nueva API key
5. Copia la key en tu archivo `.env`

**ğŸ’¡ Nota**: La aplicaciÃ³n funciona solo con `OPENROUTER_API_KEY`. Las configuraciones de Upstash son opcionales para funcionalidades avanzadas de base de conocimiento.

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Bun** v1.0+ instalado ([Descargar aquÃ­](https://bun.sh))
- **Node.js** v18+ (opcional, para npm/yarn)
- Cuenta en **OpenRouter.ai** (gratuita)
- **Git** para clonar el repositorio

### Pasos de InstalaciÃ³n

#### 1. **Clonar el Repositorio**

```bash
git clone https://github.com/Lostovayne/Architecture-of-an-AI-app.git
cd appai
```

#### 2. **Instalar Dependencias**

```bash
# Instalar todas las dependencias del workspace
bun install

# Esto instalarÃ¡ automÃ¡ticamente:
# - Dependencias del servidor (Express, OpenAI, Zod, etc.)
# - Dependencias del cliente (React, Vite, TailwindCSS, etc.)
# - DevDependencies (Prettier, Husky, etc.)
```

#### 3. **Configurar Variables de Entorno**

```bash
# Crear archivo de entorno
touch packages/server/.env

# Editar el archivo (reemplaza con tu editor favorito)
nano packages/server/.env
```

**Contenido mÃ­nimo del `.env`:**

```env
OPENROUTER_API_KEY=sk-or-v1-tu-api-key-aqui
```

#### 4. **Verificar ConfiguraciÃ³n**

```bash
# Verificar que Bun estÃ© instalado
bun --version

# Verificar estructura del proyecto
ls -la packages/
```

#### 5. **Ejecutar en Modo Desarrollo**

```bash
# Ejecutar ambos servicios simultÃ¡neamente
bun dev
```

**Esto iniciarÃ¡:**

- ğŸ–¥ï¸ **Frontend**: http://localhost:5173 (Vite dev server)
- ğŸ”§ **Backend**: http://localhost:3000 (Express server)
- ğŸ”„ **Proxy**: Requests `/api/*` â†’ Backend automÃ¡ticamente

### âœ… VerificaciÃ³n de InstalaciÃ³n

#### Test RÃ¡pido del Backend

```bash
# En otra terminal
curl http://localhost:3000/api/chat
# DeberÃ­a responder: Hello World!
```

#### Test Completo

```bash
# Test de chat simple
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Hola mundo",
    "conversationId": "550e8400-e29b-41d4-a716-446655440000"
  }'
```

### ğŸ”§ Comandos de Desarrollo

```bash
# ğŸš€ Desarrollo completo (ambos servicios)
bun dev

# ğŸ”§ Solo servidor (con auto-reload)
cd packages/server && bun dev

# ğŸŒ Solo cliente (con HMR)
cd packages/client && bun dev

# ğŸ“¦ Build de producciÃ³n
bun run build

# ğŸš€ Iniciar servidor de producciÃ³n
bun start
```

### ğŸ¨ Comandos de Calidad

```bash
# âœ¨ Formatear todo el cÃ³digo
bun run format

# ğŸ” Lint del cliente
cd packages/client && bun run lint

# ğŸ§¹ Fix automÃ¡tico de lint
cd packages/client && bun run lint --fix
```

### ğŸ› Troubleshooting ComÃºn

#### âŒ Error: "OPENROUTER_API_KEY is not defined"

```bash
# SoluciÃ³n: Verificar el archivo .env
cat packages/server/.env
# Debe contener: OPENROUTER_API_KEY=tu-key-aqui
```

#### âŒ Error: "Port 3000 is already in use"

```bash
# SoluciÃ³n: Cambiar puerto en .env
echo "PORT=3001" >> packages/server/.env
```

#### âŒ Error: "Command 'bun' not found"

```bash
# Instalar Bun
curl -fsSL https://bun.sh/install | bash
# Reiniciar terminal
```

#### âŒ Frontend no carga la API

```bash
# Verificar proxy en vite.config.ts
# Debe apuntar al puerto correcto del servidor
```

### ğŸ”„ ActualizaciÃ³n del Proyecto

```bash
# Actualizar dependencias
bun update

# Reinstalar desde cero si hay problemas
rm -rf node_modules packages/*/node_modules bun.lockb
bun install
```

## ğŸ“¡ API Endpoints Completa

### ğŸ”¥ Chat Principal (POST /api/chat)

**Endpoint principal para interacciones con la IA hÃ­brida**

```http
POST /api/chat
Content-Type: application/json

{
  "prompt": "Tu mensaje aquÃ­",
  "conversationId": "uuid-opcional",
  "modelType": "simple|memory|with_tools",
  "taskType": "chat|image|audio|vision",
  "useMemory": true|false,
  "useKnowledgeBase": true|false
}
```

#### ğŸ“‹ ParÃ¡metros de Request

| ParÃ¡metro          | Tipo    | Requerido | Valores                            | DescripciÃ³n                                       |
| ------------------ | ------- | --------- | ---------------------------------- | ------------------------------------------------- |
| `prompt`           | string  | âœ… SÃ­     | 1-1000 chars                       | El mensaje del usuario                            |
| `conversationId`   | string  | âœ… SÃ­     | UUID v4                            | ID Ãºnico de conversaciÃ³n                          |
| `modelType`        | string  | âŒ No     | `simple`, `memory`, `with_tools`   | Tipo de modelo (default: `simple`)                |
| `taskType`         | string  | âŒ No     | `chat`, `image`, `audio`, `vision` | Tipo de tarea (default: `chat`)                   |
| `useMemory`        | boolean | âŒ No     | `true`, `false`                    | Activar memoria conversacional (default: `false`) |
| `useKnowledgeBase` | boolean | âŒ No     | `true`, `false`                    | Activar base de conocimiento (default: `false`)   |

#### ğŸ“¤ Respuesta Exitosa (200)

```json
{
   "message": "Respuesta generada por la IA",
   "conversationId": "uuid-de-conversacion",
   "modelUsed": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
   "toolsUsed": ["retrieveConversationMemory", "addResource"]
}
```

#### âŒ Respuestas de Error

**400 - Error de ValidaciÃ³n**

```json
{
   "_errors": [],
   "prompt": {
      "_errors": ["Prompt is required"]
   },
   "conversationId": {
      "_errors": ["Invalid uuid"]
   }
}
```

**500 - Error del Servidor**

```json
{
   "error": "Failed to generate response"
}
```

### ğŸ” Health Check (GET /api/chat)

**Verificar que el servidor estÃ¡ funcionando**

```http
GET /api/chat
```

**Respuesta:**

```text
Hello World!
```

## ğŸ¤– Modelos de IA Disponibles

### ğŸ“Š Tabla de ComparaciÃ³n de Modelos

| Modelo                   | Provider   | Herramientas | VisiÃ³n | Streaming | Max Tokens | Uso Recomendado         |
| ------------------------ | ---------- | ------------ | ------ | --------- | ---------- | ----------------------- |
| **Dolphin Mistral 24B**  | OpenRouter | âŒ No        | âŒ No  | âœ… SÃ­     | 250        | Chat rÃ¡pido sin censura |
| **Llama 4 Scout**        | OpenRouter | âœ… SÃ­        | âŒ No  | âœ… SÃ­     | 400        | Chat con herramientas   |
| **Gemini 2.5 Flash**     | OpenRouter | âŒ No        | âŒ No  | âŒ No     | 0          | GeneraciÃ³n de imÃ¡genes  |
| **Llama 3.2 11B Vision** | OpenRouter | âœ… SÃ­        | âœ… SÃ­  | âœ… SÃ­     | 500        | AnÃ¡lisis de imÃ¡genes    |

### ğŸ¯ Tipos de Modelo (ModelType)

#### 1. `simple` - Chat BÃ¡sico

- **Modelo**: `cognitivecomputations/dolphin-mistral-24b-venice-edition:free`
- **CaracterÃ­sticas**: Sin herramientas, respuestas rÃ¡pidas, sin censura
- **Uso**: Conversaciones casuales, respuestas directas
- **Tokens**: 250 max

```json
{
   "prompt": "ExplÃ­came quÃ© es React",
   "conversationId": "uuid",
   "modelType": "simple"
}
```

#### 2. `memory` - Chat con Memoria

- **Modelo**: `meta-llama/llama-4-scout:free`
- **CaracterÃ­sticas**: Memoria conversacional, contexto inteligente
- **Uso**: Conversaciones largas que requieren contexto
- **Tokens**: 400 max
- **Herramientas**: Memoria conversacional automÃ¡tica

```json
{
   "prompt": "Â¿Recuerdas lo que te dije sobre mi trabajo?",
   "conversationId": "uuid",
   "modelType": "memory",
   "useMemory": true
}
```

#### 3. `with_tools` - Chat con Herramientas Completas

- **Modelo**: `meta-llama/llama-4-scout:free`
- **CaracterÃ­sticas**: Todas las herramientas disponibles
- **Uso**: Tareas complejas, aprendizaje, bÃºsqueda
- **Tokens**: 400 max
- **Herramientas**: Memoria + Base de conocimiento

```json
{
   "prompt": "Aprende esto: Next.js 14 incluye App Router",
   "conversationId": "uuid",
   "modelType": "with_tools",
   "useMemory": true,
   "useKnowledgeBase": true
}
```

### ğŸ”§ Herramientas Disponibles

#### 1. **Memoria Conversacional** (`retrieveConversationMemory`)

- **FunciÃ³n**: Busca informaciÃ³n especÃ­fica en el historial de conversaciÃ³n
- **ParÃ¡metros**:
   - `query`: QuÃ© buscar ("cuando hablamos de X")
   - `timeframe`: `recent`, `middle`, `beginning`, `all`
- **ActivaciÃ³n**: `useMemory: true`

#### 2. **Base de Conocimiento** (`addResource` / `getInformation`)

- **addResource**: Almacena informaciÃ³n nueva
- **getInformation**: Busca informaciÃ³n almacenada
- **ParÃ¡metros**:
   - `resource`: Contenido a almacenar
   - `query`: BÃºsqueda en la base de conocimiento
- **ActivaciÃ³n**: `useKnowledgeBase: true`

### ğŸš€ SelecciÃ³n AutomÃ¡tica de Modelos

El `modelSelectorService` selecciona automÃ¡ticamente el modelo Ã³ptimo basado en:

1. **Tipo de tarea** (`taskType`):
   - `image` â†’ Gemini Flash (futuro)
   - `vision` â†’ Llama Vision (futuro)
   - `chat` â†’ SelecciÃ³n inteligente

2. **Herramientas requeridas**:
   - Sin herramientas â†’ Dolphin Mistral
   - Con herramientas â†’ Llama Scout

3. **ConfiguraciÃ³n del usuario**:
   - `modelType` especificado
   - `useMemory` / `useKnowledgeBase`

## ğŸ§ª Ejemplos de Uso y Testing

### 1. ğŸ¤– Chat BÃ¡sico (Dolphin Mistral)

```javascript
// Ejemplo de chat simple y rÃ¡pido
const response = await fetch('/api/chat', {
   method: 'POST',
   headers: { 'Content-Type': 'application/json' },
   body: JSON.stringify({
      prompt: 'ExplÃ­came quÃ© es React en tÃ©rminos simples',
      conversationId: crypto.randomUUID(),
      modelType: 'simple',
   }),
});

const data = await response.json();
console.log(data.message);
// Modelo usado: dolphin-mistral-24b-venice-edition
// Herramientas: []
```

### 2. ğŸ§  Chat con Memoria Conversacional

```javascript
const conversationId = crypto.randomUUID();

// Establecer informaciÃ³n personal
await fetch('/api/chat', {
   method: 'POST',
   headers: { 'Content-Type': 'application/json' },
   body: JSON.stringify({
      prompt: 'Soy Alex, tengo 28 aÃ±os y soy fullstack developer especializado en Node.js',
      conversationId,
      modelType: 'memory',
      useMemory: true,
   }),
});

// Luego preguntar sobre la informaciÃ³n
await fetch('/api/chat', {
   method: 'POST',
   headers: { 'Content-Type': 'application/json' },
   body: JSON.stringify({
      prompt: 'Â¿PodrÃ­as resumir mi perfil profesional?',
      conversationId,
      modelType: 'memory',
      useMemory: true,
   }),
});
// La IA recordarÃ¡ la informaciÃ³n previa
```

### 3. ğŸ“š Base de Conocimiento

```javascript
// EnseÃ±ar informaciÃ³n nueva
await fetch('/api/chat', {
   method: 'POST',
   headers: { 'Content-Type': 'application/json' },
   body: JSON.stringify({
      prompt: 'Aprende esto: Vite es un build tool que usa esbuild para pre-bundling rÃ¡pido',
      conversationId: crypto.randomUUID(),
      modelType: 'with_tools',
      useKnowledgeBase: true,
   }),
});

// Consultar informaciÃ³n aprendida
await fetch('/api/chat', {
   method: 'POST',
   headers: { 'Content-Type': 'application/json' },
   body: JSON.stringify({
      prompt: 'Â¿QuÃ© sabes sobre herramientas de build modernas?',
      conversationId: crypto.randomUUID(),
      modelType: 'with_tools',
      useKnowledgeBase: true,
   }),
});
```

### 4. ğŸ¯ Chat HÃ­brido Completo

```javascript
// Combina memoria + conocimiento + herramientas
await fetch('/api/chat', {
   method: 'POST',
   headers: { 'Content-Type': 'application/json' },
   body: JSON.stringify({
      prompt: 'BasÃ¡ndote en mi perfil y lo que sabes sobre herramientas, Â¿deberÃ­a usar Vite?',
      conversationId: conversationId, // Usa la misma conversaciÃ³n con memoria
      modelType: 'with_tools',
      useMemory: true,
      useKnowledgeBase: true,
   }),
});
// Combina informaciÃ³n personal + conocimiento tÃ©cnico
```

## ğŸ§ª Herramientas de Testing

### 1. ğŸŒ Frontend Visual (`test-frontend.html`)

```bash
# Abrir en navegador para testing visual interactivo
open test-frontend.html
# o
python -m http.server 8080  # Servir desde localhost
```

**CaracterÃ­sticas:**

- âœ… Interface visual intuitiva
- âœ… Tests de todos los tipos de modelo
- âœ… Respuestas en tiempo real
- âœ… InformaciÃ³n de modelo y herramientas usadas

### 2. ğŸ¤– Tests Automatizados (`test-automated.js`)

```bash
# Ejecutar suite completa de tests
node test-automated.js
```

**Tests incluidos:**

- Chat simple con Dolphin Mistral
- Establecimiento y prueba de memoria
- EnseÃ±anza y consulta de conocimiento
- Chat hÃ­brido completo
- GeneraciÃ³n de reporte JSON

### 3. âš¡ Tests con cURL (`test-curl.sh`)

```bash
# Ejecutar tests rÃ¡pidos con cURL
chmod +x test-curl.sh
./test-curl.sh
```

**CaracterÃ­sticas:**

- âœ… Tests rÃ¡pidos desde terminal
- âœ… Salida formateada con jq
- âœ… UUIDs predefinidos para consistency

### 4. ğŸ“¬ ColecciÃ³n Insomnia (`insomnia-collection.json`)

```bash
# Importar en Insomnia para testing manual
# File â†’ Import Data â†’ insomnia-collection.json
```

## ğŸ” Monitoreo y Debugging

### Logs del Servidor

```bash
# Logs detallados en consola
cd packages/server && bun dev

# Salida esperada:
# ğŸ“¥ Request recibido: {...}
# âœ… Request validado: {...}
# ğŸš€ Llamando a chatService...
# ğŸ¤– Modelo seleccionado: dolphin-mistral-24b-venice-edition
# ğŸ”§ Soporta herramientas: false
# âœ… Respuesta exitosa: {...}
```

### ValidaciÃ³n de Response

```javascript
// Estructura de respuesta estÃ¡ndar
{
  "message": "Contenido de la respuesta",
  "conversationId": "uuid-v4",
  "modelUsed": "nombre-del-modelo-usado",
  "toolsUsed": ["herramienta1", "herramienta2"] // Array de herramientas ejecutadas
}
```

## ğŸ”’ Consideraciones de Seguridad y ProducciÃ³n

### ğŸ›¡ï¸ Seguridad

- âš ï¸ **Uso Responsable**: Sistema diseÃ±ado para conversaciones libres sin censura
- ğŸ” **API Keys**: Nunca commitees tu `OPENROUTER_API_KEY` al repositorio
- ï¿½ **Gitignore**: El `.env` ya estÃ¡ incluido en `.gitignore`
- ï¿½ğŸ›¡ï¸ **Rate Limiting**: Considera implementar rate limiting en producciÃ³n
- ğŸ“Š **Monitoreo**: Implementa logging y monitoreo para uso en producciÃ³n
- ğŸ”’ **CORS**: Configura CORS apropiadamente para tu dominio

### ğŸš€ Despliegue en ProducciÃ³n

#### PreparaciÃ³n para ProducciÃ³n

```bash
# 1. Build del cliente
cd packages/client && bun run build

# 2. Verificar que dist/ se creÃ³ correctamente
ls packages/client/dist/

# 3. El servidor sirve automÃ¡ticamente los archivos estÃ¡ticos
```

#### Variables de Entorno de ProducciÃ³n

```env
# ProducciÃ³n recomendada
NODE_ENV=production
PORT=3000
OPENROUTER_API_KEY=tu-key-de-produccion

# Opcionales para funcionalidades avanzadas
UPSTASH_VECTOR_REST_URL=tu-url-vector
UPSTASH_VECTOR_REST_TOKEN=tu-token-vector
UPSTASH_SEARCH_REST_URL=tu-url-search
UPSTASH_SEARCH_REST_TOKEN=tu-token-search

# Sistema personalizado
SYSTEM_PROMPT="Tu prompt personalizado de producciÃ³n"
```

#### Deploy en Vercel/Netlify

```bash
# Configurar como proyecto fullstack
# Frontend: packages/client/
# Backend: packages/server/ (como API)
```

### ğŸ“ˆ Escalabilidad y Performance

#### Optimizaciones Implementadas

- **ğŸ§  Context Management**: GestiÃ³n inteligente de contexto para conversaciones largas
- **ğŸ”„ Model Selection**: SelecciÃ³n automÃ¡tica del modelo Ã³ptimo segÃºn la tarea
- **ğŸ’¾ Memory Tools**: Herramientas de memoria eficientes para historial largo
- **âš¡ Caching**: Cache de prompts con `prompt_cache_key` en OpenRouter

#### MÃ©tricas de Performance

| Modelo          | Tiempo Respuesta Promedio | Tokens/Segundo | Costo por 1K Tokens |
| --------------- | ------------------------- | -------------- | ------------------- |
| Dolphin Mistral | ~2-3 segundos             | ~80-100        | Gratis              |
| Llama Scout     | ~3-5 segundos             | ~60-80         | Gratis              |
| Gemini Flash    | ~1-2 segundos             | N/A            | Gratis              |

## ğŸŒ ConfiguraciÃ³n Avanzada

### ğŸ”§ ConfiguraciÃ³n de Proxy (Vite)

```typescript
// packages/client/vite.config.ts
export default defineConfig({
   server: {
      proxy: {
         '/api': {
            target: 'http://localhost:3000',
            changeOrigin: true,
            secure: false,
         },
      },
   },
});
```

### ğŸ›ï¸ ConfiguraciÃ³n del Servidor

```typescript
// packages/server/index.ts
const app = express();

// Middleware personalizado
app.use(express.json({ limit: '10mb' }));
app.use('/api/chat', router);

// Servir archivos estÃ¡ticos del cliente
app.use(express.static(clientDistPath));

// SPA fallback para React Router
app.use(
   history({
      rewrites: [
         {
            from: /^\/api\/.*$/,
            to: function (context) {
               return context.parsedUrl.pathname;
            },
         },
      ],
   })
);
```

### ï¿½ Upstash Configuration (Opcional)

Para habilitar la base de conocimiento avanzada:

```bash
# 1. Crear cuenta en Upstash
# 2. Crear Vector Database
# 3. Crear Search Index
# 4. Agregar credentials al .env
```

```env
UPSTASH_VECTOR_REST_URL=https://tu-vector-url.upstash.io
UPSTASH_VECTOR_REST_TOKEN=tu-token-aqui
UPSTASH_SEARCH_REST_URL=https://tu-search-url.upstash.io
UPSTASH_SEARCH_REST_TOKEN=tu-search-token-aqui
```

## ğŸ“š Arquitectura Interna

### ğŸ”„ Flujo de Procesamiento

```mermaid
sequenceDiagram
    participant C as Cliente
    participant API as API Controller
    participant CS as Chat Service
    participant MS as Model Selector
    participant CM as Context Manager
    participant CR as Conversation Repo
    participant OR as OpenRouter

    C->>API: POST /api/chat
    API->>API: Validar con Zod
    API->>CS: sendMessage()
    CS->>MS: selectModel()
    CS->>CM: getOptimizedContext()
    CM->>CR: getConversationHistory()
    CS->>OR: chat.completions.create()
    OR-->>CS: AI Response
    CS->>CR: addMessageToConversation()
    CS-->>API: ChatResponse
    API-->>C: JSON Response
```

### ğŸ—ï¸ PatrÃ³n de Servicios

```typescript
// SeparaciÃ³n clara de responsabilidades
â”œâ”€â”€ Controllers/     # Manejo de requests HTTP
â”œâ”€â”€ Services/        # LÃ³gica de negocio
â”œâ”€â”€ Repositories/    # Acceso a datos
â”œâ”€â”€ Tools/          # Herramientas de IA
â””â”€â”€ Types/          # Definiciones TypeScript
```

## ğŸ“‹ Esquemas de ValidaciÃ³n Completos

### Chat Request Schema (Zod)

```typescript
const chatSchema = z.object({
   prompt: z
      .string()
      .trim()
      .min(1, 'Prompt is required')
      .max(1000, 'Prompt is too long (max 1000 characters)'),
   conversationId: z.uuid('Invalid conversation ID format'),
   modelType: z.nativeEnum(ModelType).optional().default(ModelType.SIMPLE),
   taskType: z.nativeEnum(TaskType).optional().default(TaskType.CHAT),
   useMemory: z.boolean().optional().default(false),
   useKnowledgeBase: z.boolean().optional().default(false),
});
```

### TypeScript Interfaces

```typescript
// Tipos de modelos
export enum ModelType {
   SIMPLE = 'simple',
   WITH_TOOLS = 'with_tools',
   MEMORY = 'memory',
}

// Tipos de tareas
export enum TaskType {
   CHAT = 'chat',
   IMAGE = 'image',
   AUDIO = 'audio',
   VISION = 'vision',
}

// Request completa
export interface ChatRequest {
   prompt: string;
   conversationId: string;
   modelType?: ModelType;
   taskType?: TaskType;
   useMemory?: boolean;
   useKnowledgeBase?: boolean;
}

// Response completa
export interface ChatResponse {
   id: string;
   message: string;
   modelUsed: string;
   toolsUsed?: string[];
   conversationId: string;
}

// ConfiguraciÃ³n de modelo
export interface ModelConfig {
   name: string;
   provider: 'openrouter' | 'openai' | 'anthropic' | 'custom';
   supports: {
      tools: boolean;
      vision: boolean;
      streaming: boolean;
   };
   maxTokens: number;
   costPer1KTokens?: number;
}
```

## ğŸ“Š Estructura de Datos y Storage

### Conversation Repository

```typescript
// Storage en memoria (Map)
const conversations = new Map<
   string,
   Array<{ role: 'user' | 'assistant' | 'system'; content: string }>
>();

// MÃ©todos disponibles
export const conversationRepository = {
   addMessageToConversation(conversationId: string, message: Message): void,
   getConversationHistory(conversationId: string): Message[],
};
```

### Memory Tool Data Structure

```typescript
// Resultado de bÃºsqueda en memoria
interface MemorySearchResult {
   found: boolean;
   message: string;
   context?: string;
   timeframe: 'recent' | 'middle' | 'beginning' | 'all';
   totalMessages: number;
}
```

## ğŸ”„ Changelog y Actualizaciones

### VersiÃ³n Actual (v1.0.0)

#### âœ¨ CaracterÃ­sticas Principales

- âœ… Sistema hÃ­brido multi-modelo (Dolphin Mistral + Llama Scout)
- âœ… Herramientas de memoria conversacional avanzada
- âœ… Base de conocimiento con Upstash Vector
- âœ… SelecciÃ³n automÃ¡tica inteligente de modelos
- âœ… GestiÃ³n optimizada de contexto para conversaciones largas
- âœ… API RESTful completa con validaciÃ³n Zod
- âœ… Frontend React moderno con TailwindCSS
- âœ… Tests automatizados y herramientas de desarrollo

#### ğŸ”§ Mejoras TÃ©cnicas

- âœ… TypeScript en todo el stack
- âœ… Workspace monorepo con Bun
- âœ… Hot reloading para desarrollo
- âœ… Proxy automÃ¡tico frontend/backend
- âœ… Logging detallado para debugging

#### ğŸ§ª Herramientas de Testing

- âœ… Suite de tests automatizados (Node.js)
- âœ… Tests con cURL para terminal
- âœ… Interface visual para testing (HTML)
- âœ… ColecciÃ³n Insomnia para API testing

### ğŸš€ PrÃ³ximas Actualizaciones (Roadmap)

#### v1.1.0 - Modelos Multimodales

- ğŸ”® Soporte completo para Llama Vision
- ğŸ”® GeneraciÃ³n de imÃ¡genes con Gemini Flash
- ğŸ”® Procesamiento de audio y voz
- ğŸ”® Upload y anÃ¡lisis de archivos

#### v1.2.0 - Persistencia Avanzada

- ğŸ”® Base de datos PostgreSQL/MongoDB
- ğŸ”® Sistema de usuarios y autenticaciÃ³n
- ğŸ”® Conversaciones compartidas
- ğŸ”® ExportaciÃ³n de conversaciones

#### v1.3.0 - Features Avanzadas

- ğŸ”® Streaming de respuestas en tiempo real
- ğŸ”® Rate limiting inteligente
- ğŸ”® Dashboard de analytics
- ğŸ”® Plugin system para herramientas custom

### ğŸ“ Notas de MigraciÃ³n

Si actualizas desde una versiÃ³n anterior:

1. **Variables de entorno**: Nuevas variables opcionales para Upstash
2. **API**: Nuevos parÃ¡metros opcionales (backward compatible)
3. **Dependencies**: Ejecutar `bun install` para nuevas dependencias

## ğŸ¤ Contribuciones y Desarrollo

### ğŸ”§ Setup para Contribuidores

```bash
# 1. Fork del repositorio
git clone https://github.com/tu-usuario/Architecture-of-an-AI-app.git
cd appai

# 2. Crear rama para feature
git checkout -b feature/nueva-funcionalidad

# 3. Instalar dependencias
bun install

# 4. Configurar git hooks
bun prepare

# 5. Ejecutar tests
node test-automated.js
```

### ğŸ“‹ Guidelines de ContribuciÃ³n

1. **Code Style**: Usar Prettier para formateo automÃ¡tico
2. **Commits**: Seguir conventional commits (`feat:`, `fix:`, `docs:`)
3. **Testing**: Agregar tests para nuevas funcionalidades
4. **TypeScript**: Mantener tipado fuerte sin `any`
5. **Documentation**: Actualizar README para cambios de API

### ğŸ› Reportar Issues

Template para reportar bugs:

```markdown
**DescripciÃ³n del bug**
DescripciÃ³n clara del problema

**Pasos para reproducir**

1. Ir a '...'
2. Hacer click en '....'
3. Ver error

**Comportamiento esperado**
Lo que deberÃ­a suceder

**Screenshots**
Si es aplicable

**Entorno:**

- OS: [Windows/Mac/Linux]
- Bun version: [ejecutar `bun --version`]
- Node version: [ejecutar `node --version`]
```

### ğŸŒŸ Contributors

- **Lostovayne** - Autor original y mantenedor principal
- Open for contributions! ï¿½

## ï¿½ğŸ“„ Licencia y Legal

Este proyecto estÃ¡ bajo la **Licencia MIT**. Ver archivo `LICENSE` para detalles completos.

### âš–ï¸ Resumen de la Licencia MIT

- âœ… **Uso comercial** permitido
- âœ… **ModificaciÃ³n** permitida
- âœ… **DistribuciÃ³n** permitida
- âœ… **Uso privado** permitido
- âŒ **Sin garantÃ­a** incluida
- âŒ **Sin responsabilidad** del autor

### ğŸ”’ Disclaimer de Uso

Este sistema de IA estÃ¡ diseÃ±ado para conversaciones libres sin censura. Los usuarios son responsables del contenido generado y deben usar la herramienta de manera Ã©tica y legal segÃºn las leyes de su jurisdicciÃ³n.

### ğŸ·ï¸ Atribuciones

- **OpenRouter.ai** - Proveedor de modelos de IA
- **Upstash** - Servicios de base de datos vectorial
- **Radix UI** - Componentes de interface
- **TailwindCSS** - Framework de estilos
- **React Team** - Biblioteca de UI
- **Bun Team** - Runtime y herramientas

---

## ğŸ‘¨â€ğŸ’» InformaciÃ³n del Autor

**Lostovayne**

- ğŸ™ GitHub: [@Lostovayne](https://github.com/Lostovayne)
- ğŸ“§ Issues: [Reportar problema](https://github.com/Lostovayne/Architecture-of-an-AI-app/issues)
- ğŸŒŸ Stars: Â¡Dale una estrella si te gustÃ³ el proyecto!

---

<div align="center">

âš¡ **Construido con tecnologÃ­as modernas para conversaciones de IA sin lÃ­mites** âš¡

[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg)](https://github.com/Lostovayne)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-20232A?logo=react&logoColor=61DAFB)](https://reactjs.org/)
[![Bun](https://img.shields.io/badge/Bun-000000?logo=bun&logoColor=white)](https://bun.sh/)

</div>

import { GoogleGenAI } from '@google/genai';
import { Redis } from '@upstash/redis';
import { Search } from '@upstash/search';
import * as crypto from 'crypto-js';
import * as fs from 'node:fs';
import * as path from 'node:path';
import { conversationRepository } from '../repositories/conversation.repository';
import type { ChatRequest, ChatResponse } from '../types/model.types';
import { MessageRole, TaskType } from '../types/model.types';

// Configuraci√≥n de GoogleGenAI
const ai = new GoogleGenAI({
   apiKey: process.env.GEMINI_API_KEY,
});

// Configuraci√≥n de Redis para chats temporales
const redis = new Redis({
   url: process.env.UPSTASH_REDIS_REST_URL,
   token: process.env.UPSTASH_REDIS_REST_TOKEN,
});

// Configuraci√≥n de Upstash Search para conocimiento persistente
let searchClient: Search | null = null;
let knowledgeIndex: any = null;

try {
   searchClient = new Search({
      url: process.env.UPSTASH_SEARCH_REST_URL,
      token: process.env.UPSTASH_SEARCH_REST_TOKEN,
   });
   knowledgeIndex = searchClient.index('user-knowledge');
   console.log('‚úÖ Upstash Search inicializado correctamente');
} catch (error: unknown) {
   console.warn(
      '‚ö†Ô∏è Upstash Search no disponible:',
      error instanceof Error ? error.message : 'Error desconocido'
   );
}

// Implementaci√≥n de herramientas de memoria
async function storeUserInfo(
   info: string,
   category: string = 'general'
): Promise<{ success: boolean; message: string }> {
   try {
      if (!knowledgeIndex) {
         console.warn('üö® Sistema de conocimiento no disponible');
         return { success: false, message: 'Sistema de memoria no disponible' };
      }

      console.log(`üíæ Almacenando informaci√≥n del usuario [${category}]:`, info.substring(0, 100));

      const id = crypto.SHA256(info + category).toString();
      const timestamp = new Date().toISOString();

      const dataToStore = {
         id,
         content: info,
         metadata: {
            category,
            timestamp,
            type: 'user_knowledge',
            source: 'gemini_conversation',
         },
      };

      await knowledgeIndex.upsert(dataToStore);
      console.log('‚úÖ Informaci√≥n almacenada en base de conocimiento');

      return { success: true, message: 'Informaci√≥n almacenada correctamente' };
   } catch (error) {
      console.error('‚ùå Error al almacenar informaci√≥n del usuario:', error);
      return { success: false, message: 'Error al almacenar informaci√≥n' };
   }
}

async function recallUserInfo(query: string): Promise<{
   results: Array<{ content: string; category: string; timestamp: string; score: number }>;
   count: number;
   message?: string;
}> {
   try {
      if (!knowledgeIndex) {
         console.warn('üö® Sistema de conocimiento no disponible');
         return { results: [], count: 0, message: 'Sistema de memoria no disponible' };
      }

      console.log('üîç Buscando informaci√≥n del usuario:', query);

      const searchResult = await knowledgeIndex.search({
         query,
         topK: 5,
         filter: { metadata: { type: 'user_knowledge' } },
      });

      const results = searchResult?.results || [];
      console.log(`üìä Encontrados ${results.length} resultados`);

      const formattedResults = results.map(
         (result: {
            content: string;
            metadata?: { category?: string; timestamp?: string };
            score?: number;
         }) => ({
            content: result.content,
            category: result.metadata?.category || 'general',
            timestamp: result.metadata?.timestamp || '',
            score: result.score || 0,
         })
      );

      return { results: formattedResults, count: results.length };
   } catch (error) {
      console.error('‚ùå Error al buscar informaci√≥n del usuario:', error);
      return { results: [], count: 0, message: 'Error al buscar informaci√≥n' };
   }
}

async function storeTempData(
   key: string,
   data: string
): Promise<{ success: boolean; message: string }> {
   try {
      const prefixedKey = `temp:${key}`;
      await redis.setex(prefixedKey, 86400, data); // 24 horas = 86400 segundos
      console.log(`üíæ Datos temporales almacenados: ${key}`);
      return { success: true, message: 'Datos temporales almacenados (24h)' };
   } catch (error) {
      console.error('‚ùå Error al almacenar datos temporales:', error);
      return { success: false, message: 'Error al almacenar datos temporales' };
   }
}

async function getTempData(
   key: string
): Promise<{ success: boolean; data?: string; message: string }> {
   try {
      const prefixedKey = `temp:${key}`;
      const data = await redis.get(prefixedKey);

      if (data) {
         console.log(`üì¶ Datos temporales recuperados: ${key}`);
         return { success: true, data: data as string, message: 'Datos encontrados' };
      } else {
         console.log(`üîç No se encontraron datos temporales: ${key}`);
         return { success: false, message: 'Datos no encontrados o expirados' };
      }
   } catch (error) {
      console.error('‚ùå Error al recuperar datos temporales:', error);
      return { success: false, message: 'Error al recuperar datos temporales' };
   }
}

// Directorio para guardar im√°genes generadas
const IMAGES_DIR = path.join(process.cwd(), 'generated-images');
if (!fs.existsSync(IMAGES_DIR)) {
   fs.mkdirSync(IMAGES_DIR, { recursive: true });
}

// Servicio principal de Gemini optimizado
export const geminiService = {
   // Chat inteligente con herramientas
   async sendMessage(request: ChatRequest): Promise<ChatResponse> {
      try {
         console.log('üöÄ Iniciando chat con Gemini 2.5 Pro:', {
            taskType: request.taskType,
            useKnowledgeBase: request.useKnowledgeBase,
         });

         const { prompt, conversationId, taskType, useKnowledgeBase } = request;

         // Seleccionar modelo seg√∫n la tarea
         let modelName = 'gemini-2.5-flash-lite'; // Por defecto el m√°s econ√≥mico

         switch (taskType) {
            case TaskType.VISION:
               modelName = 'gemini-2.5-flash';
               break;
            case TaskType.AUDIO:
            case TaskType.TEXT_TO_SPEECH:
            case TaskType.SPEECH_TO_TEXT:
               modelName = 'gemini-2.5-flash-preview-tts';
               break;
            case TaskType.CHAT:
            default:
               modelName = 'gemini-2.5-flash-lite';
               break;
         }

         console.log(`ü§ñ Usando modelo: ${modelName}`);

         // Buscar informaci√≥n relevante del usuario autom√°ticamente
         let contextInfo = '';
         if (useKnowledgeBase && knowledgeIndex) {
            try {
               const userInfo = await recallUserInfo(
                  `contexto relevante para: ${prompt.substring(0, 50)}`
               );
               if (userInfo.results && userInfo.results.length > 0) {
                  contextInfo = userInfo.results
                     .slice(0, 2)
                     .map((r: { content: string }) => r.content)
                     .join('. ');
                  console.log('‚úÖ Contexto del usuario cargado');
               }
            } catch (error) {
               console.log('‚ö†Ô∏è Error al cargar contexto del usuario:', error);
            }
         }

         // Preparar prompt con contexto
         let finalPrompt = prompt;
         if (contextInfo) {
            finalPrompt = `Contexto previo del usuario: ${contextInfo}\n\nUsuario actual: ${prompt}`;
         }

         // Almacenar mensaje del usuario
         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.USER,
            content: prompt,
         });

         // Tambi√©n almacenar en Redis (temporal)
         const redisKey = `chat:${conversationId}:${Date.now()}`;
         await redis.setex(
            redisKey,
            86400,
            JSON.stringify({
               role: 'user',
               content: prompt,
               timestamp: new Date().toISOString(),
            })
         );

         console.log('üí¨ Enviando mensaje a Gemini...');
         const response = await ai.models.generateContent({
            model: modelName,
            contents: finalPrompt,
         });

         const content = response.candidates?.[0]?.content?.parts?.[0]?.text || 'Sin respuesta';
         const toolsUsed: string[] = [];

         // Si el usuario comparti√≥ informaci√≥n personal, almacenarla autom√°ticamente
         if (useKnowledgeBase && this.detectsPersonalInfo(prompt)) {
            try {
               await storeUserInfo(prompt, 'conversacion_automatica');
               toolsUsed.push('auto_memory_storage');
               console.log('üíæ Informaci√≥n personal detectada y almacenada autom√°ticamente');
            } catch (error) {
               console.log('‚ö†Ô∏è Error al almacenar informaci√≥n autom√°ticamente:', error);
            }
         }

         // Almacenar respuesta del asistente
         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.ASSISTANT,
            content,
         });

         // Tambi√©n almacenar en Redis (temporal)
         const responseRedisKey = `chat:${conversationId}:${Date.now() + 1}`;
         await redis.setex(
            responseRedisKey,
            86400,
            JSON.stringify({
               role: 'assistant',
               content,
               timestamp: new Date().toISOString(),
               toolsUsed,
            })
         );

         return {
            id: crypto.SHA256(conversationId + Date.now()).toString(),
            message: content,
            modelUsed: modelName,
            toolsUsed,
            conversationId,
            usage: {
               promptTokens: finalPrompt.length / 4, // Estimaci√≥n
               completionTokens: content.length / 4,
               totalTokens: (finalPrompt.length + content.length) / 4,
            },
         };
      } catch (error: unknown) {
         console.error('‚ùå Error en Gemini service:', error);

         const errorMessage = error instanceof Error ? error.message : 'Error desconocido';

         throw {
            code: 'GEMINI_API_ERROR',
            message: `Error de Gemini API: ${errorMessage}`,
            details: {
               provider: 'Gemini',
               originalError: errorMessage,
            },
            timestamp: new Date(),
         };
      }
   },

   // Generaci√≥n REAL de im√°genes con Gemini
   async generateImage(
      prompt: string,
      conversationId: string,
      options: {
         style?: string;
         quality?: string;
         aspectRatio?: string;
      } = {}
   ): Promise<ChatResponse> {
      try {
         console.log('üé® Generando imagen REAL con Gemini 2.5 Flash Image Preview...');

         // Crear prompt mejorado seg√∫n el estilo
         let enhancedPrompt = prompt;

         if (options.style === 'photorealistic') {
            enhancedPrompt = `Create a photorealistic, high-quality image: ${prompt}`;
         } else if (options.style === 'artistic') {
            enhancedPrompt = `Create an artistic, painterly style image: ${prompt}`;
         } else if (options.style === 'cartoon') {
            enhancedPrompt = `Create a cartoon style, animated, colorful image: ${prompt}`;
         } else if (options.style === 'abstract') {
            enhancedPrompt = `Create an abstract art, conceptual image: ${prompt}`;
         }

         console.log('üìù Prompt optimizado:', enhancedPrompt);

         const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image-preview',
            contents: enhancedPrompt,
         });

         let imageUrl = null;
         let imageBuffer = null;
         let content = 'Imagen generada correctamente';

         // Procesar la respuesta para extraer la imagen
         if (response.candidates?.[0]?.content?.parts) {
            for (const part of response.candidates[0].content.parts) {
               if (part.text) {
                  content = part.text;
               } else if (part.inlineData) {
                  // Imagen encontrada como datos inline
                  imageBuffer = Buffer.from(part.inlineData.data, 'base64');

                  // Guardar imagen en el servidor
                  const filename = `gemini-image-${Date.now()}.png`;
                  const filepath = path.join(IMAGES_DIR, filename);
                  fs.writeFileSync(filepath, imageBuffer);

                  // Crear URL para acceder a la imagen
                  imageUrl = `/generated-images/${filename}`;
                  content = `‚úÖ Imagen generada exitosamente: ${filename}`;

                  console.log(`üñºÔ∏è Imagen guardada en: ${filepath}`);
                  break;
               }
            }
         }

         // Almacenar en conversaci√≥n
         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.USER,
            content: `Generar imagen: ${prompt}`,
         });

         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.ASSISTANT,
            content: imageUrl ? `Imagen generada: ${imageUrl}` : content,
         });

         const responseData: ChatResponse = {
            id: crypto.SHA256(conversationId + Date.now()).toString(),
            message: content,
            modelUsed: 'gemini-2.5-flash-image-preview',
            toolsUsed: ['native_image_generation'],
            conversationId,
            usage: {
               promptTokens: enhancedPrompt.length / 4,
               completionTokens: content.length / 4,
               totalTokens: (enhancedPrompt.length + content.length) / 4,
            },
         };

         // Agregar imagen si se gener√≥
         if (imageUrl && imageBuffer) {
            responseData.images = [
               {
                  type: 'image',
                  imageUrl: { url: imageUrl },
                  metadata: {
                     format: 'png',
                     prompt: enhancedPrompt,
                     style: options.style || 'default',
                     size: `${imageBuffer.length} bytes`,
                  },
               },
            ];
         }

         return responseData;
      } catch (error: unknown) {
         console.error('‚ùå Error generando imagen con Gemini:', error);

         const errorMessage = error instanceof Error ? error.message : 'Error desconocido';

         throw {
            code: 'IMAGE_GENERATION_ERROR',
            message: `Error generando imagen: ${errorMessage}`,
            details: { provider: 'Gemini Image Preview', originalError: errorMessage },
            timestamp: new Date(),
         };
      }
   },

   // Generaci√≥n de audio con TTS
   async generateAudio(prompt: string, conversationId: string): Promise<ChatResponse> {
      try {
         console.log('üéµ Generando audio con Gemini TTS...');

         const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-preview-tts',
            contents: `Convert this text to speech: ${prompt}`,
         });

         const content = response.candidates?.[0]?.content?.parts?.[0]?.text || 'Audio generado';

         // Almacenar en conversaci√≥n
         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.USER,
            content: `Generar audio: ${prompt}`,
         });

         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.ASSISTANT,
            content,
         });

         return {
            id: crypto.SHA256(conversationId + Date.now()).toString(),
            message: content,
            modelUsed: 'gemini-2.5-flash-preview-tts',
            toolsUsed: ['audio_generation'],
            conversationId,
         };
      } catch (error: unknown) {
         console.error('‚ùå Error generando audio:', error);

         const errorMessage = error instanceof Error ? error.message : 'Error desconocido';

         throw {
            code: 'AUDIO_GENERATION_ERROR',
            message: `Error generando audio: ${errorMessage}`,
            details: { provider: 'Gemini TTS', originalError: errorMessage },
            timestamp: new Date(),
         };
      }
   },

   // Generaci√≥n de video
   async generateVideo(prompt: string, conversationId: string): Promise<ChatResponse> {
      try {
         console.log('üé¨ Iniciando generaci√≥n de video...');

         const operation = await ai.models.generateVideos({
            model: 'veo-3.0-generate-001',
            prompt: prompt,
         });

         // Polling hasta que el video est√© listo
         let videoOperation = operation;
         let attempts = 0;
         const maxAttempts = 30; // 5 minutos m√°ximo

         while (!videoOperation.done && attempts < maxAttempts) {
            console.log(`‚è≥ Generando video... Intento ${attempts + 1}/${maxAttempts}`);
            await new Promise((resolve) => setTimeout(resolve, 10000)); // 10 segundos

            videoOperation = await ai.operations.getVideosOperation({
               operation: videoOperation,
            });
            attempts++;
         }

         if (!videoOperation.done) {
            throw new Error('Timeout: La generaci√≥n de video tom√≥ demasiado tiempo');
         }

         // Descargar el video generado
         const filename = `gemini-video-${Date.now()}.mp4`;
         const downloadPath = path.join(IMAGES_DIR, filename);

         await ai.files.download({
            file: videoOperation.response.generatedVideos[0].video,
            downloadPath,
         });

         const videoUrl = `/generated-images/${filename}`;
         const content = `‚úÖ Video generado exitosamente: ${filename}`;

         console.log(`üé¨ Video guardado en: ${downloadPath}`);

         // Almacenar en conversaci√≥n
         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.USER,
            content: `Generar video: ${prompt}`,
         });

         await conversationRepository.addMessage(conversationId, {
            role: MessageRole.ASSISTANT,
            content: `Video generado: ${videoUrl}`,
         });

         return {
            id: crypto.SHA256(conversationId + Date.now()).toString(),
            message: content,
            modelUsed: 'veo-3.0-generate-001',
            toolsUsed: ['video_generation'],
            conversationId,
            images: [
               {
                  type: 'video',
                  imageUrl: { url: videoUrl },
                  metadata: {
                     format: 'mp4',
                     prompt: prompt,
                     processingTime: `${attempts * 10}s`,
                  },
               },
            ],
         };
      } catch (error: unknown) {
         console.error('‚ùå Error generando video:', error);

         const errorMessage = error instanceof Error ? error.message : 'Error desconocido';

         throw {
            code: 'VIDEO_GENERATION_ERROR',
            message: `Error generando video: ${errorMessage}`,
            details: { provider: 'Veo 3.0', originalError: errorMessage },
            timestamp: new Date(),
         };
      }
   },

   // Detectar informaci√≥n personal en el prompt
   detectsPersonalInfo(prompt: string): boolean {
      const personalKeywords = [
         'me llamo',
         'mi nombre es',
         'soy',
         'trabajo en',
         'vivo en',
         'mi edad',
         'tengo',
         'me gusta',
         'prefiero',
         'odio',
         'mi trabajo',
         'mi familia',
         'mis hobbies',
         'mi casa',
      ];

      return personalKeywords.some((keyword) =>
         prompt.toLowerCase().includes(keyword.toLowerCase())
      );
   },

   // Limpiar datos temporales
   async cleanupTempData(): Promise<void> {
      try {
         console.log('üßπ Limpiando datos temporales...');
         console.log('‚úÖ Limpieza autom√°tica configurada con Redis TTL');
      } catch (error) {
         console.error('‚ùå Error en limpieza de datos temporales:', error);
      }
   },
};
